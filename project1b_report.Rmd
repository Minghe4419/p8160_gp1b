---
title: "Project1(B) Report"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Standard regression models assume that observations are independent and normally distributed. However, real-world data, especially in longitudinal studies, frequently violate these assumptions. Observations collected from the same subject over time tend to be correlated, and response distributions are often non-normal, exhibiting skewness or heavy tails. Failing to account for these characteristics can lead to biased parameter estimates, incorrect Type I error rates, and misleading confidence intervals.

To investigate the impact of these assumption violations, we designed a simulation study that generates longitudinal Poisson data with an autoregressive (AR(1)) correlation structure. We then assessed the performance of different statistical models in analyzing this data. First, we examined Ordinary Least Squares (OLS) regression which assumes independent and normally distributed errors. Because OLS does not account for within-subject correlation, its estimates and standard errors may be unreliable when applied to correlated count data. To address these limitations, we evaluated an alternative approach: Generalized Estimating Equations (GEE). The GEE framework provides robust standard errors and explicitly models correlation within subjects using a working correlation structure, improving efficiency in parameter estimation.

We assess bias, Type I error rates, and coverage probabilities of confidence intervals under varying levels of within-subject correlation. By highlighting the limitations of naive regression models and the advantages of GEE, our study provides insights into the appropriate statistical methods for handling correlated, non-normal data in longitudinal research.

## Project 1: Multivariate Non-Normal Distributions and Correlated Data

### Distributions and correlation

- We intend to generate longitudinal data.

- Target correlation structure is AR(1) or exchangeable correlation.

### Data generation method

```{r}
set.seed(123)  # for reproducibility

# Define sizes and parameters
n     <- 200    # number of subjects
t     <- 4      # number of repeated measurements per subject
beta0 <- -1.0   # intercept on logit scale
beta1 <-  0.3   # effect of time on logit scale
sigma <-  1.0   # std dev of random intercept (b_i)

# Create a data frame with one row per subject-time combination
# We'll store each subject's random intercept in 'b_i'.
dat <- data.frame(
  id   = rep(1:n, each = t),
  time = rep(1:t,     times = n)
)

# Simulate one random intercept per subject
# Then replicate that intercept across all time points for that subject.
b_i <- rnorm(n, mean = 0, sd = sigma)
dat$b_i <- b_i[dat$id]   # match the random intercept to each row

# Compute probability p_ij = logistic(beta0 + beta1*time_j + b_i)
# Then draw Y_ij ~ Bernoulli(p_ij).
dat$p_ij <- plogis(beta0 + beta1 * dat$time + dat$b_i)
dat$Y    <- rbinom(n * t, size = 1, prob = dat$p_ij)

head(dat)
```

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

#    Simply show the binary response Y.
ggplot(dat, aes(x = factor(Y))) +
  geom_bar(width = 0.4, fill = "steelblue") +
  xlab("Outcome Y (0 or 1)") +
  ylab("Count") +
  ggtitle("Distribution of Binary Outcome (Non-Normal)")

# each row becomes a subject
dat_wide <- dat %>%
  select(id, time, Y) %>%
  pivot_wider(names_from = time,
              values_from = Y,
              names_prefix = "Y_")

# Now dat_wide has columns: id, Y_1, Y_2, ... up to Y_t
pairwise_corr <- cor(dat_wide[, -1]) 
pairwise_corr
#> This matrix shows the sample correlation among times 1..t,

# which clearly prove that outcomes are not independent
pairs(
  dat_wide[, -1] + matrix(runif(nrow(dat_wide)*(ncol(dat_wide)-1), 0, 0.1),
                          nrow(dat_wide), ncol(dat_wide)-1),
  main = "Pairs Plot (Jittered) of Y_t across times"
)



```


### Simulation study 1
Model Fitting:
We applied OLS regression model, using the model:Count∼X
even though OLS assumes continuous, normally distributed errors and independent observations. This deliberate misspecification allowed us to observe the impact of ignoring the count nature and correlation of the data.

Simulation Settings:
We ran the simulation for 500 replicates under each combination of:
Sample Sizes: 100, 500, and 1000 subjects.
Correlation Levels: p,ranging from 0 to 0.9.
Base Mean: λ base =5.

For each replicate, we recorded:

The estimated effect of X(beta1_hat)
The bias (calculated as beta1_hat-beta1
Whether the 95% confidence interval for beta1 contained the true value.
The p-value for the predictor X to determine if the null hypothesis is rejected.


Results
Our simulation results showed that the naive OLS model produced inconsistent performance across different conditions:

Bias: 
Although the overall bias in the estimated effect of X was small on average, there were certain correlation levels (especially in moderate to high ranges of ρ) where the bias increased noticeably.
Larger sample sizes helped stabilize the estimates somewhat, but did not fully eliminate the spikes in bias observed at specific correlation levels.

Type I Error Rate: 
Contrary to the assumption of maintaining a nominal 5% error rate, the Type I error rates often exceeded this threshold, sometimes substantially.
The lack of a monotonic pattern suggests that ignoring within-subject correlation makes the hypothesis test results erratic, leading to inflated false-positive conclusions.

Coverage Probability: 
Coverage in this setting is neither stable nor monotonic as the correlation changes. The 95% confidence intervals for β₁ frequently failed to capture the true value, resulting in coverage probabilities that were lower than the nominal 95%.Coverage probability ideally should be around 95%.



### Simulation study 2

```{r}
pacman::p_load(geepack,MASS,Matrix,ggplot2, reshape2, ggcorrplot)

#--------------------------------------------------------------------------#
##### Generating the data #####
# Function to generate Longitudinal Multivariate Poisson Data
generate_longitudinal_poisson <- function(n_subjects, n_time, rho, lambda_base, beta1) {
  # Step 1: AR(1) correlation matrix
  Sigma <- outer(1:n_time, 1:n_time, function(i, j) rho^abs(i - j))
  Sigma <- as.matrix(nearPD(Sigma)$mat)  # Ensure positive definiteness
  
  # Step 2: Generate subject-specific latent normal effects
  subject_random_effects <- mvrnorm(n_subjects, mu = rep(0, n_time), Sigma = Sigma)
  
  # Step 3: Assign binary predictor (50% probability)
  subject_data <- data.frame(
    Subject = 1:n_subjects,
    X = rbinom(n_subjects, 1, 0.5)  # Binary predictor (0 or 1)
  )
  
  # Step 4: Expand into long format for longitudinal structure
  long_data <- merge(
    subject_data,
    data.frame(Time = rep(1:n_time, times = n_subjects), Subject = rep(1:n_subjects, each = n_time)),
    by = "Subject"
  )
  
  # Step 5: Assign latent normal effect to each subject-time combination
  long_data$Z <- as.vector(subject_random_effects)
  
  # Step 6: Compute Poisson mean (lambda) using log-link with covariate
  long_data$Lambda <- lambda_base * exp(beta1 * long_data$X + long_data$Z)
  
  # Step 7: Generate Poisson counts
  long_data$Count <- rpois(n_subjects * n_time, lambda = long_data$Lambda)
  
  return(long_data)
}
```

```{r}
# Example: Generate longitudinal Poisson data for 1000 subjects over 5 time points

longitudinal_poisson_data <- generate_longitudinal_poisson(n_subjects = 100000, 
                                                           n_time = 5, 
                                                           rho = 0.5, 
                                                           lambda_base = 5, 
                                                           beta1 = 0.3)
# Print first few rows
head(longitudinal_poisson_data)

# Plot Poisson Counts Over Time
ggplot(longitudinal_poisson_data, aes(x = Time, y = Count, group = Subject, color = as.factor(X))) +
  geom_line(alpha = 0.3) +
  geom_point(alpha = 0.3) +
  labs(title = "Simulated Longitudinal Poisson Data with Predictor", x = "Time", y = "Count", color = "X (Predictor)") +
  theme_minimal()

# Compare Count Distributions for X=0 vs X=1
ggplot(longitudinal_poisson_data, aes(x = Count, fill = as.factor(X))) +
  geom_histogram(binwidth = 1, position = "dodge", alpha = 0.7) +
  scale_fill_manual(values = c("blue", "red"), labels = c("X=0", "X=1")) +
  labs(title = "Distribution of Poisson Counts by Predictor X",
       x = "Poisson Count", fill = "Predictor X") +
  theme_minimal()

# Reshape data for correlation check
cor_data <- dcast(longitudinal_poisson_data, Subject ~ Time, value.var = "Count")

# Compute correlation matrix
cor_matrix <- cor(cor_data[, -1], use = "pairwise.complete.obs")

# Plot correlation heatmap  
ggcorrplot(cor_matrix, method = "circle", type = "lower", lab = TRUE) +
  labs(title = "Correlation Between Time Points in Longitudinal Poisson Data")
```

```{r}
#--------------------------------------------------------------------------#
##### running a linear regression #####

# Define simulation parameters
sample_sizes <- c(50, 100, 200, 300, 400)  # Varying sample sizes
rho_levels <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)  # Varying correlation levels
lambda_bases <- c(0.1, 5, 10, 15, 20, 25, 30, 35, 40)  # Base Poisson mean
n_time <- 5  # Fixed number of time points
beta1_null <- 0  # Set beta1 = 0 to compute Type I error rate
n_sim <- 500  # More replications for stable estimates

# Expand grid to create all parameter combinations
test_conditions <- expand.grid(n_subjects = sample_sizes, 
                               rho = rho_levels,
                               lambda_base = lambda_bases)





# Function to fit an incorrect OLS model while varying non-normality & tracking Type I Error
simulate_ols_analysis <- function(n_subjects, n_time, rho, lambda_base, beta1, n_sim) {
  type1_errors <- numeric(n_sim)
  bias_values <- numeric(n_sim)
  coverage_values <- numeric(n_sim)  # Stores whether CI contains true beta1
  
  for (i in 1:n_sim) {
    
    # Generate Poisson data
    sim_data <- generate_longitudinal_poisson(n_subjects, n_time, rho, lambda_base, beta1)
    
    # Fit OLS model **(Task 3 explicitly requires incorrect OLS)**
    lm_model <- lm(Count ~ X, data = sim_data)  
    
    # Extract p-value for predictor X
    p_value <- summary(lm_model)$coefficients["X", "Pr(>|t|)"]
    type1_errors[i] <- ifelse(p_value < 0.05, 1, 0)
    
    # Compute bias
    beta1_hat <- coef(lm_model)["X"]
    bias_values[i] <- beta1_hat - beta1
    
    # Compute 95% CI for beta1
    beta1_se <- summary(lm_model)$coefficients["X", "Std. Error"]
    beta1_CI <- beta1_hat + c(-1.96, 1.96) * beta1_se
    
    # Check if CI contains true beta1
    coverage_values[i] <- (beta1_CI[1] <= beta1 & beta1_CI[2] >= beta1)
  }
  
  # Compute average Type I Error, Bias, and Coverage
  type1_error_rate <- mean(type1_errors)
  avg_bias <- mean(bias_values)
  coverage_prob <- mean(coverage_values)
  
  # Print diagnostics
  cat("n_subjects:", n_subjects, "rho:", rho, 
      "Lambda:", lambda_base, "Type I Error Rate:", type1_error_rate, "Coverage:", coverage_prob, "\n")
  
  return(data.frame(
    n_subjects = n_subjects,
    rho = rho,
    lambda_base = lambda_base,
    avg_bias = avg_bias,
    type1_error_rate = type1_error_rate,
    coverage_prob = coverage_prob
  ))
}


# Run simulations
set.seed(123)
simulation_results_ols <- do.call(rbind, apply(test_conditions, 1, function(row) {
  simulate_ols_analysis(n_subjects = row["n_subjects"], 
                        n_time = n_time, 
                        rho = row["rho"], 
                        lambda_base = row["lambda_base"], 
                        beta1 = beta1_null,
                        n_sim = n_sim)  
}))
```

```{r}
# Plot Bias vs. Correlation
ggplot(simulation_results_ols, aes(x = rho, y = avg_bias, color = as.factor(lambda_base))) +
  geom_line() + geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(title = "Bias in OLS Regression Across Correlation and Non-Normality Levels",
       x = "Correlation Level", y = "Bias",
       color = "Lambda") +
  theme_minimal()

ggplot(simulation_results_ols, aes(x = lambda_base, y = avg_bias, color = as.factor(rho))) +
  geom_line() + geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(title = "Bias in OLS Regression Across Correlation and Non-Normality Levels",
       x = "Lambda", y = "Bias",
       color = "Correlation Level") +
  theme_minimal()

library(dplyr)
library(ggplot2)

# 1) Identify the numeric max(lambda_base) and min(rho)
max_lambda <- max(simulation_results_ols$lambda_base)
min_rho    <- min(simulation_results_ols$rho)

# 2) Create subsets using a tolerance (in case of floating-point mismatch)
df_max_lambda <- filter(simulation_results_ols, abs(lambda_base - max_lambda) < 1e-8)
df_min_rho    <- filter(simulation_results_ols, abs(rho - min_rho) < 1e-8)

# 3) Now plot from these subsets:

#--- Plot 1: Type I Error Rate vs. Correlation (lambda_base = max)
ggplot(df_max_lambda, aes(x = rho, y = type1_error_rate)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(
    title = "Type I Error Rate in OLS Regression (lambda_base = max)",
    x = "Correlation Level",
    y = "Type I Error Rate"
  ) +
  theme_minimal()

#--- Plot 2: Type I Error Rate vs. Lambda (rho = min)
ggplot(df_min_rho, aes(x = lambda_base, y = type1_error_rate)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(
    title = "Type I Error Rate in OLS Regression (rho = min)",
    x = "Lambda",
    y = "Type I Error Rate"
  ) +
  theme_minimal()

#--- Plot 3: Coverage Probability vs. Correlation (lambda_base = max)
ggplot(df_max_lambda, aes(x = rho, y = coverage_prob)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(
    title = "Coverage Probability of Confidence Intervals (lambda_base = max)",
    x = "Correlation Level",
    y = "Coverage Probability"
  ) +
  theme_minimal()

#--- Plot 4: Coverage Probability vs. Lambda (rho = min)
ggplot(df_min_rho, aes(x = lambda_base, y = coverage_prob)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(
    title = "Coverage Probability of Confidence Intervals (rho = min)",
    x = "Lambda",
    y = "Coverage Probability"
  ) +
  theme_minimal()

```



```{r}
#--------------------------------------------------------------------------#
##### running a GEE poisson regression #####

simulate_gee_analysis <- function(n_subjects, n_time, rho, lambda_base, beta1, n_sim) {
  type1_errors <- numeric(n_sim)
  bias_values <- numeric(n_sim)
  coverage_values <- numeric(n_sim)
  
  for (i in 1:n_sim) {
    
    # Generate Poisson-distributed correlated data
    sim_data <- generate_longitudinal_poisson(n_subjects, n_time, rho, lambda_base, beta1)
    
    # Fit a **correct** GEE model
    gee_model <- geeglm(Count ~ X, id = Subject, data = sim_data, family = poisson, corstr = "ar1")
    
    # Extract p-value for predictor X
    p_value <- summary(gee_model)$coefficients["X", "Pr(>|W|)"]
    type1_errors[i] <- ifelse(p_value < 0.05, 1, 0)
    
    # Compute bias
    beta1_hat <- coef(gee_model)["X"]
    bias_values[i] <- beta1_hat - beta1
    
    # Compute 95% CI
    beta1_se <- summary(gee_model)$coefficients["X", "Std.err"]
    beta1_CI <- beta1_hat + c(-1.96, 1.96) * beta1_se
    
    # Check if CI contains true beta1
    coverage_values[i] <- (beta1_CI[1] <= beta1 & beta1_CI[2] >= beta1)
  }
  
  # Compute average Type I Error, Bias, and Coverage
  type1_error_rate <- mean(type1_errors)
  avg_bias <- mean(bias_values)
  coverage_prob <- mean(coverage_values)
  
  # Print diagnostics
  cat("n_subjects:", n_subjects, "rho:", rho,
      "Lambda:", lambda_base, "Type I Error Rate (GEE):", type1_error_rate, "Coverage (GEE):", coverage_prob, "\n")
  
  return(data.frame(
    n_subjects = n_subjects,
    rho = rho,
    lambda_base = lambda_base,
    avg_bias = avg_bias,
    type1_error_rate = type1_error_rate,
    coverage_prob = coverage_prob
  ))
}

# Run simulations
set.seed(123)
simulation_results_gee <- do.call(rbind, apply(test_conditions, 1, function(row) {
  simulate_gee_analysis(n_subjects = row["n_subjects"], 
                        n_time = n_time, 
                        rho = row["rho"], 
                        lambda_base = row["lambda_base"], 
                        beta1 = beta1_null,
                        n_sim = n_sim)  
}))
```

```{r}
# First, compute max(lambda_base) and min(rho) for the GEE simulation results
max_lambda_gee <- max(simulation_results_gee$lambda_base)
min_rho_gee <- min(simulation_results_gee$rho)

# Create subsets using a small tolerance
df_max_lambda_gee <- simulation_results_gee %>% 
  filter(abs(lambda_base - max_lambda_gee) < 1e-8)
df_min_rho_gee <- simulation_results_gee %>% 
  filter(abs(rho - min_rho_gee) < 1e-8)

# Plot 1: Type I Error Rate vs. Correlation (for lambda_base = max)
ggplot(df_max_lambda_gee, aes(x = rho, y = type1_error_rate)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(title = "Type I Error Rate in GEE Regression (lambda_base = max)",
       x = "Correlation Level (rho)", 
       y = "Type I Error Rate") +
  theme_minimal()

# Plot 2: Type I Error Rate vs. Lambda (for rho = min)
ggplot(df_min_rho_gee, aes(x = lambda_base, y = type1_error_rate)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(title = "Type I Error Rate in GEE Regression (rho = min)",
       x = "Lambda Base", 
       y = "Type I Error Rate") +
  theme_minimal()

# Plot 3: Coverage Probability vs. Correlation (for lambda_base = max)
ggplot(df_max_lambda_gee, aes(x = rho, y = coverage_prob)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(title = "Coverage Probability in GEE Regression (lambda_base = max)",
       x = "Correlation Level (rho)", 
       y = "Coverage Probability") +
  theme_minimal()

# Plot 4: Coverage Probability vs. Lambda (for rho = min)
ggplot(df_min_rho_gee, aes(x = lambda_base, y = coverage_prob)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ n_subjects, scales = "fixed") +
  labs(title = "Coverage Probability in GEE Regression (rho = min)",
       x = "Lambda Base", 
       y = "Coverage Probability") +
  theme_minimal()


```

```{r}
#--------------------------------------------------------------------------#
##### Model comparison #####

simulation_results_gee$model <- "GEE"
simulation_results_ols$model <- "OLS"

# Combine the results
comparison_results <- rbind(simulation_results_gee, simulation_results_ols)

ggplot(filter(comparison_results, lambda_base==max(lambda_base)), aes(x = rho, y = avg_bias, color = model, linetype = model)) +
  geom_line(size = 1) + geom_point(size = 2) +
  facet_wrap(~ n_subjects, scales = "fixed") +  
  labs(title = "Bias in OLS vs GEE Regression",
       x = "Correlation Level", y = "Bias",
       color = "Model Type", linetype = "Model Type") +
  theme_minimal()


ggplot(filter(comparison_results, lambda_base==max(lambda_base)), aes(x = rho, y = type1_error_rate, color = model, linetype = model)) +
  geom_line(size = 1) + geom_point(size = 2) +
  facet_wrap(~ n_subjects, scales = "fixed") +  
  labs(title = "Type I Error Rate: OLS vs GEE",
       x = "Correlation Level", y = "Type I Error Rate",
       color = "Model Type", linetype = "Model Type") +
  theme_minimal()


ggplot(filter(comparison_results, lambda_base==max(lambda_base)), aes(x = rho, y = coverage_prob, color = model, linetype = model)) +
  geom_line(size = 1) + geom_point(size = 2) +
  facet_wrap(~ n_subjects, scales = "fixed") +  
  labs(title = "Coverage Probability of Confidence Intervals: OLS vs GEE",
       x = "Correlation Level", y = "Coverage Probability",
       color = "Model Type", linetype = "Model Type") +
  theme_minimal()


```

